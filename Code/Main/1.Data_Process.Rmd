---
title: "1. Data Processing - Corn & Soy"
author: "Jaeseok Hwang"
date: "`r Sys.Date()`"
output: html_document
---

# Setup

```{r setup, message=FALSE, warning=FALSE, results='hide'}
library(knitr)
library(here)
library(sf)
library(data.table)
library(tidyverse)
library(stringr)

# Load the modular functions
source(here("Code", "src", "functions_for_processing.R"))

# Define crops to process
crops_to_process <- c("corn", "soy")

```

# Load Metadata

```{r load, message=FALSE, warning=FALSE, results='hide'}

# Read the master parameter file (contains dates for both crops)
field_params <- read_field_params(here("Data", "Raw", "field_parameter.json"))

# Preview
head(field_params)

```

# Main Processing Loop

```{r processing loop, message=FALSE, warning=FALSE, results='hide'}

for (crop in crops_to_process) {
  
  cat(paste0("\n=========================================\n"))
  cat(paste0(" PROCESSING CROP: ", toupper(crop), "\n"))
  cat(paste0("=========================================\n"))
  
  # 1. Define Directories
  # ---------------------
  tb_dir   <- here("Data", crop, "exp_tb_data")
  bdry_dir <- here("Data", crop, "exp_bdry_data")
  out_dir  <- here("Data", crop, "analysis_Ready")
  
  if (!dir.exists(tb_dir)) {
    cat(paste("Directory not found:", tb_dir, "- Skipping.\n"))
    next
  }
  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
  
  # 2. List Fields
  # --------------
  ffy_ids <- list.files(tb_dir, pattern = "_tb.rds") %>% 
    str_remove("_tb.rds")
  
  # Filter out known bad fields if necessary (Example list)
  ignore_list <- c("15_1_2023", "27_1_2023") 
  ffy_ids <- setdiff(ffy_ids, ignore_list)
  
  cat(paste("Found", length(ffy_ids), "fields.\n"))
  
  # 3. Process Each Field
  # ---------------------
  for (ffy in ffy_ids) {
    cat(paste("  -> Processing:", ffy, "... "))
    
    skip_field <- FALSE
    
    # A. Read Spatial Data
    # --------------------
    tryCatch({
      exp_sf  <- read_exp_sf(ffy, crop)
      bdry_sf <- read_boundary(ffy, crop)
    }, error = function(e) {
      cat("FAILED reading files. Skipping.\n")
      skip_field <<- TRUE
    })
    
    if(skip_field) next
    
    # B. Process Soils (SSURGO)
    # -------------------------
    soils_sf <- get_ssurgo_props(bdry_sf)
    soils_df <- area_weight_soils(exp_sf, soils_sf)
    
    # C. Process Topography (DEM)
    # ---------------------------
    topo_df  <- get_topo_features(exp_sf, bdry_sf)
    
    # D. Process Weather (Daymet - Stage Specific)
    # --------------------------------------------
    # Calculates S1-S4 stages based on plant/harvest dates in JSON
    weather_df <- process_weather(ffy, bdry_sf, field_params)
    
    # E. Merge and Save
    # -----------------
    # Bind columns
    exp_dt <- sf::st_drop_geometry(exp_sf)
    merged_dt <- cbind(exp_dt, soils_df, topo_df)
    
    # Add Weather (Broadcast field-level weather to all subplots)
    # Note: weather_df is 1 row, merged_dt is N rows. 
    # cbind works because weather_df repeats.
    if(nrow(weather_df) > 0) {
      merged_dt <- cbind(merged_dt, weather_df %>% dplyr::select(-ffy_id))
    }
    
    # Re-attach geometry
    final_sf <- sf::st_sf(merged_dt, geometry = sf::st_geometry(exp_sf))
    
    # Save
    saveRDS(final_sf, file.path(out_dir, paste0(ffy, "_merged_data.rds")))
    cat("Done.\n")
  }
}

```


# Validation

```{r validation, message=FALSE, warning=FALSE, results='hide'}

# Check one processed file from Corn to ensure columns are correct
test_file <- list.files(here("Data", "corn", "Processed", "Analysis_Ready"), 
                        full.names = TRUE)[1]

if (!is.na(test_file)) {
  dat <- readRDS(test_file)
  print(colnames(dat))
  print(head(dat))
}

```